# -*- coding: utf-8 -*-
"""LLM_in_context_learning.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1kuy7Yjq5izSvWkrrqmUbyl3ErfQAVm_8
"""

# Build a pipeline for text-generation tasks.
import torch
from transformers import AutoTokenizer,pipeline
# model_id = "togethercomputer/Llama-2-7B-32K-Instruct"
model_id = "NousResearch/Llama-2-7b-chat-hf"


tokenizer = AutoTokenizer.from_pretrained(model_id)
pipeline = pipeline(
    "text-generation",
    model=model_id,
    tokenizer=tokenizer,
    torch_dtype=torch.float16,
    device_map="auto",
)

#############################################################
########### Test the model with mathematical task.  #########
#############################################################
prompt_template = """[INST] <>
You are a helpful, respectful and honest assistant. Answer exactly in few words.
<>

Answer the question below:

Janet's ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?

Return final results in numeric format.
[/INST]
""".strip()


sequences = pipeline(
    prompt_template,
    do_sample=True,
    top_k=10,
    temperature=0.7,
    top_p=0.95,
    num_return_sequences=1,
    eos_token_id=tokenizer.eos_token_id,
    max_length=256,
)

for seq in sequences:
    print(f"Result: {seq['generated_text']}")



#############################################################
########### Evaluate the model on a mathematical ############
########### example using zero-shot in-context learning.#####
#############################################################
prompt_template = """[INST] <>
You are a helpful, respectful and honest assistant. Answer exactly in few words.
<>

Answer the question below:

Janet's ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?

Let's think step by step then return final results in numeric format.
[/INST]
""".strip()


sequences = pipeline(
    prompt_template,
    do_sample=True,
    top_k=10,
    temperature=0.7,
    top_p=0.95,
    num_return_sequences=1,
    eos_token_id=tokenizer.eos_token_id,
    max_length=256,
)

for seq in sequences:
    print(f"Result: {seq['generated_text']}")


#############################################################
########### if have problem with GPU memory      ############
########### Then reduce the number of bits        ###########
#############################################################
import torch
from transformers import AutoTokenizer,pipeline
model_id = "NousResearch/Llama-2-7b-chat-hf"


tokenizer = AutoTokenizer.from_pretrained(model_id)
pipeline = pipeline(
    "text-generation",
    model=model_id,
    tokenizer=tokenizer,
    torch_dtype=torch.float16,
    device_map="auto",
    model_kwargs={"load_in_4bit": True}
)

prompt_template = """[INST] <>
You are a helpful, respectful and honest assistant. Answer exactly in few words.
<>

Answer the question below:

Janet's ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?
[/INST]
""".strip()


sequences = pipeline(
    prompt_template,
    do_sample=True,
    top_k=10,
    temperature=0.7,
    top_p=0.95,
    num_return_sequences=1,
    eos_token_id=tokenizer.eos_token_id,
    max_length=256,
)

for seq in sequences:
    print("*****"*50)
    print(f"Result: {seq['generated_text']}")


#############################################################
########### Create a pipeline with               ############
########### text-generation task and a small 1.1B model #####
#############################################################
import torch
from transformers import AutoTokenizer,pipeline
model_id = "TinyLlama/TinyLlama-1.1B-step-50K-105b"


tokenizer = AutoTokenizer.from_pretrained(model_id)
pipeline = pipeline(
    "text-generation",
    model=model_id,
    tokenizer=tokenizer,
    torch_dtype=torch.float16,
    device_map="auto"
    )
prompt_template = """[INST] <>
You are a helpful, respectful and honest assistant. Answer exactly in few words.
<>

Answer the question below:

Janet's ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market?
[/INST]
""".strip()


sequences = pipeline(
    prompt_template,
    do_sample=True,
    top_k=10,
    temperature=0.7,
    top_p=0.95,
    num_return_sequences=4,
    eos_token_id=tokenizer.eos_token_id,
    max_length=250
    )

for seq in sequences:
    print("*****"*50)
    print(f"Result: {seq['generated_text']}")